{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 999,
            "source": [
                "# TODO: Fix imports\n",
                "from typing import List\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.datasets import load_iris, load_breast_cancer, load_wine"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1001,
            "source": [
                "np.set_printoptions(precision=2)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1004,
            "source": [
                "def column_matrix(array: List[float]):\n",
                "  return np.array(array, ndmin=2).T\n",
                "\n",
                "def random_matrix(rows: int, columns: int):\n",
                "  return np.random.rand(rows, columns)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1008,
            "source": [
                "class MultilayerPerception:\n",
                "  def __init__(self, max_iter=200, learning_rate=0.001, tol=0.01, hidden_layer_sizes=(100,)):\n",
                "    self.max_iterations = max_iter\n",
                "    self.learning_rate = learning_rate\n",
                "    self.error_tolerance = tol\n",
                "    self.hidden_layer_sizes = hidden_layer_sizes\n",
                "\n",
                "  def fit(self, dataset, targets):\n",
                "    num_outputs, num_inputs = dataset.shape\n",
                "    layers = [num_inputs] + list(self.hidden_layer_sizes) + [num_outputs]\n",
                "\n",
                "    self.weights = [np.random.rand(layers[i], layers[i + 1]) for i in range(len(layers) - 1)]\n",
                "    self.derivatives = [np.zeros((layers[i], layers[i + 1])) for i in range(len(layers) - 1)]\n",
                "    self.activations = [np.zeros(layers[i]) for i in range(len(layers))]\n",
                "    self.targets = targets\n",
                "\n",
                "    error = 1\n",
                "    training_iteration = 0\n",
                "    while error > self.error_tolerance and training_iteration < self.max_iterations:\n",
                "      for index, sample in enumerate(dataset):\n",
                "        target = targets[index]\n",
                "        output = self._feed_forward(sample)\n",
                "        error = target - output\n",
                "\n",
                "        self._back_propagate(error)\n",
                "        self._gradient()\n",
                "\n",
                "        error = self._mse(target, output)\n",
                "      training_iteration += 1\n",
                "\n",
                "  def predict(self, X):\n",
                "    labels = list(set(self.targets))\n",
                "    predictions = self._feed_forward(X)\n",
                "    labeled_predictions = []\n",
                "\n",
                "    for prediction in predictions:\n",
                "      avg = np.average(prediction)\n",
                "      labeled_predictions.append(min(labels, key=lambda x: abs(x - avg)))\n",
                "\n",
                "    return labeled_predictions\n",
                "\n",
                "\n",
                "  def _feed_forward(self, sample):\n",
                "    activations = sample\n",
                "    self.activations[0] = activations\n",
                "\n",
                "    for index, weight in enumerate(self.weights):\n",
                "        net_inputs = np.dot(activations, weight)\n",
                "        activations = self._activate(net_inputs)\n",
                "        self.activations[index + 1] = activations\n",
                "\n",
                "    return activations\n",
                "\n",
                "  def _back_propagate(self, error):\n",
                "    for i in reversed(range(len(self.derivatives))):\n",
                "      activations = self.activations[i+1]\n",
                "      delta = error * self._activate(activations, derivate=True)\n",
                "      delta_re = delta.reshape(delta.shape[0], -1).T\n",
                "      \n",
                "      current_activations = self.activations[i]\n",
                "      current_activations = current_activations.reshape(current_activations.shape[0],-1)\n",
                "\n",
                "      self.derivatives[i] = np.dot(current_activations, delta_re)\n",
                "\n",
                "      error = np.dot(delta, self.weights[i].T)\n",
                "\n",
                "  def _gradient(self):\n",
                "    # TODO: Enumerate\n",
                "    for i in range(len(self.weights)):\n",
                "      derivatives = self.derivatives[i]\n",
                "      self.weights[i] += derivatives * self.learning_rate\n",
                "  \n",
                "  def _activate(self, sample, derivate=False):\n",
                "    sigmoid = lambda x: 1/(1 + np.exp(-x))\n",
                "    dsigmoid = lambda y: y * (1 - y)\n",
                "\n",
                "    return sigmoid(sample) if derivate == False else dsigmoid(sample)\n",
                "\n",
                "  def _mse(self, target, output):\n",
                "    return np.average((target - output) ** 2)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1013,
            "source": [
                "def test(dataset, dataset_name: str):\n",
                "  X_train, X_test, y_train, y_test = train_test_split(dataset['data'], dataset[\"target\"], random_state=42, test_size=0.3)\n",
                "\n",
                "  test_hidden_layer_sizes = [(100,), (100, 200), (50, 50, 50)]\n",
                "\n",
                "  for hidden_layer_sizes in test_hidden_layer_sizes:\n",
                "    mlp = MultilayerPerception(hidden_layer_sizes=hidden_layer_sizes)\n",
                "    mlp.fit(X_train, y_train)\n",
                "\n",
                "    predictions = mlp.predict(X_test)\n",
                "    correct_count = 0\n",
                "    for index, p in enumerate(predictions):\n",
                "      if p == y_test[index]:\n",
                "        correct_count += 1\n",
                "\n",
                "    print(f'{dataset_name} -> score is {correct_count / X_test.shape[0]} with hidden layers {hidden_layer_sizes}')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1017,
            "source": [
                "iris_data = load_iris()\n",
                "wine_data = load_wine()\n",
                "cancer_data = load_breast_cancer()\n",
                "datasets = [(iris_data, 'Iris dataset'), (wine_data, 'Wine dataset'), (cancer_data, 'Breast cancer dataset')]\n",
                "\n",
                "for (dataset, dataset_name) in datasets:\n",
                "  test(dataset, dataset_name)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Iris dataset -> score is 0.28888888888888886 with hidden layers (100,)\n",
                        "Iris dataset -> score is 0.28888888888888886 with hidden layers (100, 200)\n",
                        "Iris dataset -> score is 0.28888888888888886 with hidden layers (50, 50, 50)\n",
                        "Wine dataset -> score is 0.3888888888888889 with hidden layers (100,)\n",
                        "Wine dataset -> score is 0.3888888888888889 with hidden layers (100, 200)\n",
                        "Wine dataset -> score is 0.3888888888888889 with hidden layers (50, 50, 50)\n",
                        "Breast cancer dataset -> score is 0.631578947368421 with hidden layers (100,)\n",
                        "Breast cancer dataset -> score is 0.631578947368421 with hidden layers (100, 200)\n",
                        "Breast cancer dataset -> score is 0.631578947368421 with hidden layers (50, 50, 50)\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.0",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.0 64-bit"
        },
        "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}